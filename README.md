Resolving classification and regression problems

1. Adults

Best model: XGBoost  ~87 % accuracy

Our basic model achieved 87% accuracy with a quite stable learning curve (a bit overfitted but for the purpose of this exercise acceptable). 

2. Adults2
In this case the hyperparameters optimization (hyperopt and grid random search) was for no use.  Non of the them contibuted to a better performance. My  model got overfitted. That being said, I should work harder on my features (feature engineering) or increase the amount of data. Perhaps, the model was too sophisticated for such a simple problem and small dataset.

Summary:
Iâ€™ve learned how to use Decision Tree, Random Forest, touch a bit of feature engineering and parameter optimization. After all, validation plays a huge role and can be very helpful in further estimations.

